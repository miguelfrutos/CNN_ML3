{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmPj1VVCfWb"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovTGnGws2vzf"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrbllgAFipZ",
        "outputId": "a0ee7e16-cc17-4db2-9133-fd54288cb4b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-05 10:57:00--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.193.128, 173.194.197.128, 142.250.152.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.193.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   145MB/s    in 0.6s    \n",
            "\n",
            "2022-03-05 10:57:01 (145 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj4rXshqbQlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3285a809-7439-4b69-c6fa-fdbc599336dc"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg",
        "outputId": "0ff88be6-7efd-49b7-8fe2-cd7c55769742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4s8HckqGlnb",
        "outputId": "a7fb2ffb-bd7c-4723-d5b9-8d09c01d745a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-05 10:57:10--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.120.128, 142.251.6.128, 74.125.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.120.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   206MB/s    in 0.3s    \n",
            "\n",
            "2022-03-05 10:57:10 (206 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl9XXARuV_eg",
        "outputId": "2153be22-b8da-4770-a2c4-eb22b7c29de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA",
        "outputId": "75e0d74d-5e8a-453a-e78e-de28a1938ef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 38s - loss: 0.3272 - acc: 0.8725 - val_loss: 0.1323 - val_acc: 0.9500 - 38s/epoch - 376ms/step\n",
            "Epoch 2/10\n",
            "100/100 - 22s - loss: 0.2421 - acc: 0.9055 - val_loss: 0.0944 - val_acc: 0.9640 - 22s/epoch - 222ms/step\n",
            "Epoch 3/10\n",
            "100/100 - 24s - loss: 0.2142 - acc: 0.9165 - val_loss: 0.1505 - val_acc: 0.9450 - 24s/epoch - 236ms/step\n",
            "Epoch 4/10\n",
            "100/100 - 22s - loss: 0.2091 - acc: 0.9250 - val_loss: 0.1314 - val_acc: 0.9560 - 22s/epoch - 220ms/step\n",
            "Epoch 5/10\n",
            "100/100 - 23s - loss: 0.2073 - acc: 0.9300 - val_loss: 0.0998 - val_acc: 0.9700 - 23s/epoch - 227ms/step\n",
            "Epoch 6/10\n",
            "100/100 - 22s - loss: 0.1830 - acc: 0.9335 - val_loss: 0.1069 - val_acc: 0.9650 - 22s/epoch - 221ms/step\n",
            "Epoch 7/10\n",
            "100/100 - 23s - loss: 0.1579 - acc: 0.9510 - val_loss: 0.1180 - val_acc: 0.9650 - 23s/epoch - 226ms/step\n",
            "Epoch 8/10\n",
            "100/100 - 22s - loss: 0.1830 - acc: 0.9390 - val_loss: 0.1086 - val_acc: 0.9610 - 22s/epoch - 220ms/step\n",
            "Epoch 9/10\n",
            "100/100 - 23s - loss: 0.1707 - acc: 0.9380 - val_loss: 0.1030 - val_acc: 0.9690 - 23s/epoch - 225ms/step\n",
            "Epoch 10/10\n",
            "100/100 - 23s - loss: 0.1555 - acc: 0.9455 - val_loss: 0.1246 - val_acc: 0.9640 - 23s/epoch - 228ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8hwTr0e55BQ",
        "outputId": "5ec32266-2996-402f-a2ae-acca4c61f3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         38536192    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_J4S0Z2rgg",
        "outputId": "eae68956-ac0e-40df-8279-8398faa5f560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GgDGG4Y_hJ",
        "outputId": "37146985-8658-449c-dda1-b3011a0116e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 30s - loss: 0.1864 - acc: 0.9280 - val_loss: 0.1133 - val_acc: 0.9610 - 30s/epoch - 296ms/step\n",
            "Epoch 2/50\n",
            "100/100 - 23s - loss: 0.1692 - acc: 0.9320 - val_loss: 0.1201 - val_acc: 0.9600 - 23s/epoch - 227ms/step\n",
            "Epoch 3/50\n",
            "100/100 - 23s - loss: 0.1689 - acc: 0.9355 - val_loss: 0.1245 - val_acc: 0.9600 - 23s/epoch - 229ms/step\n",
            "Epoch 4/50\n",
            "100/100 - 22s - loss: 0.1747 - acc: 0.9325 - val_loss: 0.1254 - val_acc: 0.9590 - 22s/epoch - 221ms/step\n",
            "Epoch 5/50\n",
            "100/100 - 22s - loss: 0.1613 - acc: 0.9350 - val_loss: 0.1253 - val_acc: 0.9590 - 22s/epoch - 221ms/step\n",
            "Epoch 6/50\n",
            "100/100 - 22s - loss: 0.1657 - acc: 0.9325 - val_loss: 0.1253 - val_acc: 0.9590 - 22s/epoch - 221ms/step\n",
            "Epoch 7/50\n",
            "100/100 - 22s - loss: 0.1670 - acc: 0.9315 - val_loss: 0.1238 - val_acc: 0.9590 - 22s/epoch - 223ms/step\n",
            "Epoch 8/50\n",
            "100/100 - 22s - loss: 0.1696 - acc: 0.9290 - val_loss: 0.1239 - val_acc: 0.9590 - 22s/epoch - 224ms/step\n",
            "Epoch 9/50\n",
            "100/100 - 22s - loss: 0.1648 - acc: 0.9280 - val_loss: 0.1229 - val_acc: 0.9600 - 22s/epoch - 224ms/step\n",
            "Epoch 10/50\n",
            "100/100 - 22s - loss: 0.1814 - acc: 0.9325 - val_loss: 0.1224 - val_acc: 0.9600 - 22s/epoch - 222ms/step\n",
            "Epoch 11/50\n",
            "100/100 - 22s - loss: 0.1671 - acc: 0.9340 - val_loss: 0.1219 - val_acc: 0.9600 - 22s/epoch - 222ms/step\n",
            "Epoch 12/50\n",
            "100/100 - 22s - loss: 0.1757 - acc: 0.9295 - val_loss: 0.1213 - val_acc: 0.9600 - 22s/epoch - 225ms/step\n",
            "Epoch 13/50\n",
            "100/100 - 22s - loss: 0.1734 - acc: 0.9305 - val_loss: 0.1206 - val_acc: 0.9600 - 22s/epoch - 224ms/step\n",
            "Epoch 14/50\n",
            "100/100 - 23s - loss: 0.1713 - acc: 0.9335 - val_loss: 0.1202 - val_acc: 0.9610 - 23s/epoch - 233ms/step\n",
            "Epoch 15/50\n",
            "100/100 - 22s - loss: 0.1904 - acc: 0.9250 - val_loss: 0.1203 - val_acc: 0.9600 - 22s/epoch - 221ms/step\n",
            "Epoch 16/50\n",
            "100/100 - 23s - loss: 0.1759 - acc: 0.9310 - val_loss: 0.1198 - val_acc: 0.9610 - 23s/epoch - 233ms/step\n",
            "Epoch 17/50\n",
            "100/100 - 22s - loss: 0.1581 - acc: 0.9365 - val_loss: 0.1194 - val_acc: 0.9610 - 22s/epoch - 224ms/step\n",
            "Epoch 18/50\n",
            "100/100 - 22s - loss: 0.1687 - acc: 0.9330 - val_loss: 0.1186 - val_acc: 0.9610 - 22s/epoch - 220ms/step\n",
            "Epoch 19/50\n",
            "100/100 - 22s - loss: 0.1579 - acc: 0.9360 - val_loss: 0.1184 - val_acc: 0.9610 - 22s/epoch - 221ms/step\n",
            "Epoch 20/50\n",
            "100/100 - 22s - loss: 0.1707 - acc: 0.9325 - val_loss: 0.1177 - val_acc: 0.9600 - 22s/epoch - 222ms/step\n",
            "Epoch 21/50\n",
            "100/100 - 23s - loss: 0.1522 - acc: 0.9425 - val_loss: 0.1173 - val_acc: 0.9610 - 23s/epoch - 226ms/step\n",
            "Epoch 22/50\n",
            "100/100 - 23s - loss: 0.1562 - acc: 0.9315 - val_loss: 0.1171 - val_acc: 0.9600 - 23s/epoch - 227ms/step\n",
            "Epoch 23/50\n",
            "100/100 - 23s - loss: 0.1580 - acc: 0.9375 - val_loss: 0.1170 - val_acc: 0.9610 - 23s/epoch - 229ms/step\n",
            "Epoch 24/50\n",
            "100/100 - 23s - loss: 0.1605 - acc: 0.9355 - val_loss: 0.1159 - val_acc: 0.9600 - 23s/epoch - 230ms/step\n",
            "Epoch 25/50\n",
            "100/100 - 23s - loss: 0.1775 - acc: 0.9225 - val_loss: 0.1155 - val_acc: 0.9600 - 23s/epoch - 227ms/step\n",
            "Epoch 26/50\n",
            "100/100 - 23s - loss: 0.1559 - acc: 0.9395 - val_loss: 0.1156 - val_acc: 0.9600 - 23s/epoch - 226ms/step\n",
            "Epoch 27/50\n",
            "100/100 - 22s - loss: 0.1775 - acc: 0.9305 - val_loss: 0.1153 - val_acc: 0.9610 - 22s/epoch - 225ms/step\n",
            "Epoch 28/50\n",
            "100/100 - 23s - loss: 0.1501 - acc: 0.9310 - val_loss: 0.1148 - val_acc: 0.9600 - 23s/epoch - 227ms/step\n",
            "Epoch 29/50\n",
            "100/100 - 23s - loss: 0.1569 - acc: 0.9325 - val_loss: 0.1143 - val_acc: 0.9610 - 23s/epoch - 229ms/step\n",
            "Epoch 30/50\n",
            "100/100 - 23s - loss: 0.1627 - acc: 0.9360 - val_loss: 0.1142 - val_acc: 0.9610 - 23s/epoch - 230ms/step\n",
            "Epoch 31/50\n",
            "100/100 - 23s - loss: 0.1677 - acc: 0.9320 - val_loss: 0.1133 - val_acc: 0.9610 - 23s/epoch - 231ms/step\n",
            "Epoch 32/50\n",
            "100/100 - 23s - loss: 0.1676 - acc: 0.9300 - val_loss: 0.1128 - val_acc: 0.9610 - 23s/epoch - 229ms/step\n",
            "Epoch 33/50\n",
            "100/100 - 23s - loss: 0.1507 - acc: 0.9365 - val_loss: 0.1124 - val_acc: 0.9610 - 23s/epoch - 230ms/step\n",
            "Epoch 34/50\n",
            "100/100 - 23s - loss: 0.1692 - acc: 0.9340 - val_loss: 0.1122 - val_acc: 0.9610 - 23s/epoch - 228ms/step\n",
            "Epoch 35/50\n",
            "100/100 - 22s - loss: 0.1577 - acc: 0.9340 - val_loss: 0.1116 - val_acc: 0.9610 - 22s/epoch - 225ms/step\n",
            "Epoch 36/50\n",
            "100/100 - 22s - loss: 0.1544 - acc: 0.9375 - val_loss: 0.1119 - val_acc: 0.9610 - 22s/epoch - 224ms/step\n",
            "Epoch 37/50\n",
            "100/100 - 23s - loss: 0.1427 - acc: 0.9445 - val_loss: 0.1115 - val_acc: 0.9610 - 23s/epoch - 226ms/step\n",
            "Epoch 38/50\n",
            "100/100 - 24s - loss: 0.1516 - acc: 0.9475 - val_loss: 0.1109 - val_acc: 0.9620 - 24s/epoch - 236ms/step\n",
            "Epoch 39/50\n",
            "100/100 - 22s - loss: 0.1673 - acc: 0.9280 - val_loss: 0.1107 - val_acc: 0.9610 - 22s/epoch - 221ms/step\n",
            "Epoch 40/50\n",
            "100/100 - 23s - loss: 0.1537 - acc: 0.9425 - val_loss: 0.1105 - val_acc: 0.9610 - 23s/epoch - 230ms/step\n",
            "Epoch 41/50\n",
            "100/100 - 23s - loss: 0.1491 - acc: 0.9370 - val_loss: 0.1101 - val_acc: 0.9610 - 23s/epoch - 227ms/step\n",
            "Epoch 42/50\n",
            "100/100 - 23s - loss: 0.1643 - acc: 0.9380 - val_loss: 0.1098 - val_acc: 0.9610 - 23s/epoch - 229ms/step\n",
            "Epoch 43/50\n",
            "100/100 - 22s - loss: 0.1626 - acc: 0.9345 - val_loss: 0.1095 - val_acc: 0.9610 - 22s/epoch - 223ms/step\n",
            "Epoch 44/50\n",
            "100/100 - 23s - loss: 0.1398 - acc: 0.9420 - val_loss: 0.1087 - val_acc: 0.9620 - 23s/epoch - 229ms/step\n",
            "Epoch 45/50\n",
            "100/100 - 23s - loss: 0.1588 - acc: 0.9350 - val_loss: 0.1087 - val_acc: 0.9610 - 23s/epoch - 226ms/step\n",
            "Epoch 46/50\n",
            "100/100 - 23s - loss: 0.1640 - acc: 0.9300 - val_loss: 0.1081 - val_acc: 0.9620 - 23s/epoch - 230ms/step\n",
            "Epoch 47/50\n",
            "100/100 - 23s - loss: 0.1440 - acc: 0.9395 - val_loss: 0.1083 - val_acc: 0.9620 - 23s/epoch - 229ms/step\n",
            "Epoch 48/50\n",
            "100/100 - 23s - loss: 0.1452 - acc: 0.9435 - val_loss: 0.1083 - val_acc: 0.9610 - 23s/epoch - 230ms/step\n",
            "Epoch 49/50\n",
            "100/100 - 23s - loss: 0.1555 - acc: 0.9315 - val_loss: 0.1080 - val_acc: 0.9620 - 23s/epoch - 229ms/step\n",
            "Epoch 50/50\n",
            "100/100 - 23s - loss: 0.1434 - acc: 0.9440 - val_loss: 0.1078 - val_acc: 0.9610 - 23s/epoch - 230ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FtxcKjJfxL9",
        "outputId": "31729d29-7f61-4867-d462-5d71a475127d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUmyohAyBzh"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}